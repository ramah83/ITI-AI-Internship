{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd4e6c6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"\n",
    "        background: linear-gradient(135deg, #001127ff, #003984ff);\n",
    "        color: white; \n",
    "        padding: 15px 30px; \n",
    "        border-radius: 500px; \n",
    "        font-family: 'Segoe UI', Arial, sans-serif; \n",
    "        box-shadow: 0 4px 15px rgba(0,0,0,0.3);\n",
    "        display: inline-block;\n",
    "    \">\n",
    "       W2 C1 Day 20/8\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed22cc",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">1. Importing OS, Base64, TensorFlow, Matplotlib, and Random Libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5704f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d95c424",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">2. Loading and Displaying Information About the MNIST Dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c133847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_images is of type <class 'numpy.ndarray'>.\n",
      "training_labels is of type <class 'numpy.ndarray'>\n",
      "\n",
      "There are 60000 examples with shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
    "(training_images, training_labels), (testing_images, testing_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"training_images is of type {type(training_images)}.\\ntraining_labels is of type {type(training_labels)}\\n\")\n",
    "\n",
    "data_shape = training_images.shape\n",
    "\n",
    "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca1f8d",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">3. Normalizing Training Images to Range [0,1]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195ca8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1835948",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">4. Creating and Compiling a Neural Network Model for MNIST Classification</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "687d2844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_compile_model():\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),tf.keras.layers.Dense(128, activation='relu'),\n",
    "tf.keras.layers.Dense(10, activation='softmax')])\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88fa00e",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">5. Initializing an Untrained MNIST Classification Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3133f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_model = create_and_compile_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae63cf9",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">6. Generating Predictions with the Untrained Model and Checking Output Shape</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd828805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions have shape: (5, 10)\n"
     ]
    }
   ],
   "source": [
    "predictions = untrained_model.predict(training_images[:5], verbose=False)\n",
    "print(f\"predictions have shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e3f80",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">7. Defining a Custom EarlyStopping Callback to Halt Training at 98% Accuracy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aa35dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('accuracy') >= 0.98:\n",
    "            self.model.stop_training = True\n",
    "            print(\"\\nReached 98% accuracy so cancelling training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cacb63d",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">8. Training the MNIST Model with EarlyStopping Callback</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cca0eecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2546\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.1109\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9768 - loss: 0.0764\n",
      "Epoch 4/10\n",
      "\u001b[1m1866/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9830 - loss: 0.0566\n",
      "Reached 98% accuracy so cancelling training!\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9825 - loss: 0.0579\n"
     ]
    }
   ],
   "source": [
    "def train_mnist(training_images, training_labels):\n",
    "    model = create_and_compile_model()\n",
    "    history = model.fit(training_images, training_labels, epochs=10, callbacks=[EarlyStoppingCallback()], verbose=1)\n",
    "    return history\n",
    "training_history = train_mnist(training_images, training_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fcf687",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">9. Decoding and Printing a Base64-Encoded Answer</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8df69aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - A tf.keras.Input with the same shape as the images\n",
      "   - A Flatten layer\n",
      "   - A Dense layer with 512 units and ReLU activation function\n",
      "   - A Dense layer with 10 units and softmax activation function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_answer = \"CiAgIC0gQSB0Zi5rZXJhcy5JbnB1dCB3aXRoIHRoZSBzYW1lIHNoYXBlIGFzIHRoZSBpbWFnZXMKICAgLSBBIEZsYXR0ZW4gbGF5ZXIKICAgLSBBIERlbnNlIGxheWVyIHdpdGggNTEyIHVuaXRzIGFuZCBSZUxVIGFjdGl2YXRpb24gZnVuY3Rpb24KICAgLSBBIERlbnNlIGxheWVyIHdpdGggMTAgdW5pdHMgYW5kIHNvZnRtYXggYWN0aXZhdGlvbiBmdW5jdGlvbgo==\"\n",
    "encoded_answer = encoded_answer.encode('ascii')\n",
    "answer = base64.b64decode(encoded_answer)\n",
    "answer = answer.decode('ascii')\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da674dee",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#0E78FE\">10. Displaying a Random Training Image from the MNIST Dataset with Its Label</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9de823ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.randint(0, len(training_images)-1)\n",
    "plt.imshow(training_images[idx], cmap=\"gray\")\n",
    "plt.title(f\"Label: {training_labels[idx]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

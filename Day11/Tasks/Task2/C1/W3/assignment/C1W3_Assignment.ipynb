{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af702789",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"\n",
    "        background: linear-gradient(135deg, #38001bff, #78003aff);\n",
    "        color: white; \n",
    "        padding: 15px 30px; \n",
    "        border-radius: 500px; \n",
    "        font-family: 'Segoe UI', Arial, sans-serif; \n",
    "        box-shadow: 0 4px 15px rgba(0,0,0,0.3);\n",
    "        display: inline-block;\n",
    "    \">\n",
    "       W3 C1 Day 20/8\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817eb27a",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#821a4cff\">1. Importing OS, Base64, NumPy, and TensorFlow Libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5980e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d440fdf",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#821a4cff\">2. Loading the MNIST Dataset and Displaying Its Structure</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8600a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_images is of type <class 'numpy.ndarray'>.\n",
      "training_labels is of type <class 'numpy.ndarray'>\n",
      "\n",
      "There are 60000 examples with shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
    "(training_images, training_labels), (testing_images, testing_labels) = tf.keras.datasets.mnist.load_data()\n",
    "print(f\"training_images is of type {type(training_images)}.\\ntraining_labels is of type {type(training_labels)}\\n\")\n",
    "data_shape = training_images.shape\n",
    "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad0dc4",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#821a4cff\">3. Reshaping Images to Add a Channel Dimension and Normalizing Pixel Values</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1afcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_normalize(images):\n",
    "    images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)\n",
    "    images = images / 255.0\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580018cb",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#821a4cff\">4. Normalizing and Reshaping MNIST Training Images, Then Displaying Their Properties</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4499991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
      "\n",
      "Shape of one image after reshaping: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(training_images, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "training_images = reshape_and_normalize(training_images)\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24fefd",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#821a4cff\">5. Defining an EarlyStopping Callback to Halt Training at 99.5% Accuracy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcaec6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('accuracy') >= 0.995:\n",
    "            self.model.stop_training = True\n",
    "            print(\"\\nReached 99.5% accuracy so cancelling training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9416b",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#821a4cff\">6. Building and Compiling a Convolutional Neural Network for MNIST Classification</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4993139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),tf.keras.layers.Flatten(),tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5937eaf",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#821a4cff\">7. Training the Convolutional Neural Network with EarlyStopping at 99.5% Accuracy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4a1b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1732\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0590\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0406\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0293\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0218\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0150\n",
      "Epoch 7/10\n",
      "\u001b[1m1874/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0105\n",
      "Reached 99.5% accuracy so cancelling training!\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0124\n"
     ]
    }
   ],
   "source": [
    "model = convolutional_model()\n",
    "training_history = model.fit(training_images, training_labels, epochs=10, callbacks=[EarlyStoppingCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408ce35",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#821a4cff\">8. Decoding and Printing a Base64-Encoded Model Architecture Answer</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "175cdd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - A tf.keras.Input with a shape that matches that of every image in the training set plus the extra dimension you added\n",
      "   - A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function\n",
      "   - A MaxPooling2D layer with a pool_size of 2x2\n",
      "   - A Flatten layer with no arguments\n",
      "   - A Dense layer with 128 units and ReLU activation function\n",
      "   - A Dense layer with 10 units and softmax activation function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_answer = \"CiAgIC0gQSB0Zi5rZXJhcy5JbnB1dCB3aXRoIGEgc2hhcGUgdGhhdCBtYXRjaGVzIHRoYXQgb2YgZXZlcnkgaW1hZ2UgaW4gdGhlIHRyYWluaW5nIHNldCBwbHVzIHRoZSBleHRyYSBkaW1lbnNpb24geW91IGFkZGVkCiAgIC0gQSBDb252MkQgbGF5ZXIgd2l0aCAzMiBmaWx0ZXJzLCBhIGtlcm5lbF9zaXplIG9mIDN4MywgUmVMVSBhY3RpdmF0aW9uIGZ1bmN0aW9uCiAgIC0gQSBNYXhQb29saW5nMkQgbGF5ZXIgd2l0aCBhIHBvb2xfc2l6ZSBvZiAyeDIKICAgLSBBIEZsYXR0ZW4gbGF5ZXIgd2l0aCBubyBhcmd1bWVudHMKICAgLSBBIERlbnNlIGxheWVyIHdpdGggMTI4IHVuaXRzIGFuZCBSZUxVIGFjdGl2YXRpb24gZnVuY3Rpb24KICAgLSBBIERlbnNlIGxheWVyIHdpdGggMTAgdW5pdHMgYW5kIHNvZnRtYXggYWN0aXZhdGlvbiBmdW5jdGlvbgo=\"\n",
    "encoded_answer = encoded_answer.encode('ascii')\n",
    "answer = base64.b64decode(encoded_answer)\n",
    "answer = answer.decode('ascii')\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

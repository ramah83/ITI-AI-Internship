{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPool2D\n",
    "Activation,Dropout,BatchNormalization, Input,  Concatenate,\n",
    "GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras import Model,regularizers,Sequential\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# from tensorflow.keras.applications.efficientnet\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(12)\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(len(df)):\n",
    "    #print(df.iloc[i]['filepaths'])\n",
    "    path = '../input/100-bird-species/' + df.iloc[i]['filepaths']\n",
    "    label = df.iloc[i]['labels']\n",
    "    Type = df.iloc[i]['data set']\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    img = tf.keras.preprocessing.image.load_img(path)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(f'{label} : {Type}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=train_ds.class_names\n",
    "class_count=len(class_names)\n",
    "plt.figure(figsize=(20,20))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range (25):\n",
    "        plt.subplot(5,5,i +1)\n",
    "        img=images[i]/255         \n",
    "        plt.title(class_names[labels[i]], color='blue', fontsize=12)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                rotation_range=20, horizontal_flip=True)\n",
    "\n",
    "train_generator = train_data.flow_from_directory('train',\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                rotation_range=20, horizontal_flip=True)\n",
    "\n",
    "validation_generator = valid_data.flow_from_directory('valid',\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    img, label = train_generator.next()\n",
    "    print(img.shape) \n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "#eff_model.summary()\n",
    "vgg_model.trainable = False\n",
    "\n",
    "layer0 = Flatten(name='flatten')(vgg_model.output)\n",
    "layer1 = Dense(4096, activation='relu',name='fc1')(layer0)\n",
    "layer2 = Dense(4096, activation='relu',name='fc2')(layer1)\n",
    "out_layer = Dense(300, activation='softmax')(layer2)\n",
    "vgg_model = Model(vgg_model.input, out_layer)\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "vgg_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "              #,\n",
    "              #ModelCheckpoint(filepath='Fullmodel.{epoch:02d}-{acc:.2f}.h5', monitor='val_acc', save_best_only=False, mode='max')]\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = vgg_model.fit(\n",
    "      train_generator, \n",
    "      epochs=15,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test.flow_from_directory(\n",
    "        '../input/100-bird-species/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.evaluate(test_generator,use_multiprocessing=True,workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
    "x=base_model.output\n",
    "base_model.trainable=False # Set base model as NOT trainable initially\n",
    "x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "x=Dropout(rate=.45, seed=123)(x)        \n",
    "output=Dense(class_count, activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freezing pretrained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "model.compile(Adamax(lr=.001), loss='sparse_categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "ask_epoch=2\n",
    "rlronp=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5,  patience=1, verbose=1)\n",
    "# callbacks=[rlronp,TRC(model=model, base_model=base_model,epochs=epochs,  ask_epoch=ask_epoch)]\n",
    "history=model.fit( train_ds, validation_data=valid_ds, epochs=epochs, verbose=1, callbacks=rlronp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

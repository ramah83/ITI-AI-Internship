{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "03e4167d7aa4f0e04627d51a57684802",
     "grade": false,
     "grade_id": "cell-342b59512d5e4070",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 7 - Clustering\n",
    "\n",
    "For this assignment, you will use the *digits* dataset.\n",
    "\n",
    "The components of this assignment are:\n",
    "1. Load the digits dataset into a Pandas data frame.\n",
    "1. Preprocess the digits dataset.\n",
    "1. Examine how many clusters you may need using the elbow method and silhouette coefficient.\n",
    "1. Cluster the digits dataset using K-means and evaluate using adjusted rand index.\n",
    "1. Optional: See how the ARI changes as you alter the K-means parameters.\n",
    "1. Optional: Use clustering as a classifier and compare to Random Forest.\n",
    "1. Optional: Write your own implementation of K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d061c6263c45130af24b65591356d8a6",
     "grade": false,
     "grade_id": "cell-8cac1e0680474a0d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "76009859079aee663e58e8e46f1ad0f3",
     "grade": false,
     "grade_id": "cell-b24ccf3f1f5aad98",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 1. Load the digits dataset into a Pandas data frame (1 point)\n",
    "\n",
    "The digits dataset represents images of handwritten digits. Each image is a 32x32 bitmap. To create a numerical dataset representing the images, each image was divided into non-overlapping blocks of 4x4, and the number of set pixels in each block is counted.\n",
    "\n",
    "Thus, each image is represented by an 8x8 matrix of integers in the range 0-16. Each sample in the dataset therefore has 64 attributes. There are a total of 1,797 samples in the dataset we will use.\n",
    "\n",
    "Therefore, the digits dataset should be loaded into a Pandas dataframe with 1,797 rows and 64 columns.\n",
    "\n",
    "In this task, you will load the digits dataset (http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes) into a Pandas dataframe. Note that the final column in this dataset is the correct label (an integer in the range 0-9).\n",
    "\n",
    "Load the attributes into a Pandas dataframe named **digits**. This dataframe should *not* include the final column, as we only want to load the features here.\n",
    "\n",
    "Instead, save the final column into a Pandas series named **labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ba521f9cf5a0ebe10c5189de5509a461",
     "grade": false,
     "grade_id": "t1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes\"\n",
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61b8c5b7921adf28dd0ce4c4304126c7",
     "grade": true,
     "grade_id": "t1-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert digits.shape == (1797, 64)\n",
    "assert labels.shape[0] == 1797\n",
    "assert digits.values.sum() == 561718\n",
    "assert np.all((0 <= labels) & (labels <= 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e6ee5e4a52663ae3f8d37b6d43a40f38",
     "grade": false,
     "grade_id": "cell-825e2acaf3ee4b45",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 2. Preprocess the digits dataset (1 point)\n",
    "\n",
    "Standardize the data so that each column has a mean of (or very close to) zero and a standard deviation of (or very close to) 1. Make sure the resulting data is a Pandas dataframe (if it is not, convert it to one using pd.DataFrame). You can use `sklearn.preprocessing.scale`\n",
    "\n",
    "Note that some of the columns are all zeros across all samples. In this case, you can leave the column as is. In theory you could remove those columns as they do not contribute any information to clustering, but in our case they do not affect the results so we will keep them. For this reason, our assertions makes sure that all the columns have a standard variation of one **except** those columns that are all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c00dccbb65cf0cfffcd86ded25c8323f",
     "grade": false,
     "grade_id": "t2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1c6e229a6bd866fdbb06ec909f0b2d11",
     "grade": true,
     "grade_id": "t2-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert digits.shape == (1797, 64)\n",
    "assert np.isclose(digits.values.sum(), 0, atol=1e-4)\n",
    "assert np.all(np.isclose(digits.mean(), 0, atol=1e-4))\n",
    "assert np.all(np.isclose(digits.std(ddof=0), 1, atol=1e-4) == (digits.sum() != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6095b772a6b7b72085455f3fa33d42e3",
     "grade": false,
     "grade_id": "cell-6e46df97f5e597d8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 3. Examine how many clusters you may need using the elbow method and silhouette coefficient (1 point)\n",
    "\n",
    "The K-means algorithm requires us to specify the number of clusters. One way to assess this is using the elbow method.\n",
    "\n",
    "Use the elbow method and see if there is a clear number of clusters that make sense in the digits dataset. Note that this is just for exploratory purposes; we know the number of clusters should be 10, and that is what we will use in the future components of this exercise.\n",
    "\n",
    "The elbow method consists of visualizing the sum of squared distances between samples and their closest cluster center. This is done by creating a scatter plot where the number of clusters used in K-means is provided on the X axis and the sum of squared distances is provided on the Y axis. If there is a clear inflection point, that can be an indicator of the ideal number of clusters.\n",
    "\n",
    "Run the K-means algorithm on the digits dataset 24 times. In the first run set the number of clusters to **2**, in the second to **3**, and so on through **25**. For each run, collect the sum of squared distances. Save these into a list named **ssds**.\n",
    "\n",
    "Create an elbow plot and examine whether you can see a clear inflection point.\n",
    "\n",
    "Use silhouette_score function to calculate Silhouette Coefficient (SC)\n",
    "    from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "Explore dependence of SC on the number of clusters in K-means algorithm. Save the values to a list named **scs**.\n",
    "\n",
    "Create a plot with SC and inspect for inflection points.\n",
    "\n",
    "**Note:**\n",
    "In order for our assertions to work, make sure you use the default parameters for KMeans, with the exception of random_state, which you should set to 126, i.e. to run with one cluster:\n",
    "```python\n",
    "KMeans(n_clusters=1, random_state=126)\n",
    "```\n",
    "\n",
    "and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bfe37efa32c2bab16b0bb20c4c6791c9",
     "grade": false,
     "grade_id": "cell-762846b2ba96f881",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2fddf4dc36f5ad88ea0fb2ac63626c0d",
     "grade": true,
     "grade_id": "cell-666c6eb3182f9908",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ssds) == 24\n",
    "assert np.isclose(ssds[0], 100424, atol=1)\n",
    "assert np.isclose(np.mean(ssds), 66431, atol=1)\n",
    "\n",
    "assert len(scs) == 24\n",
    "assert np.isclose(scs[0], 0.105, atol=0.05)\n",
    "assert np.isclose(np.mean(scs), 0.138, atol=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fa38da27c184d24e2e3061f000317f9a",
     "grade": false,
     "grade_id": "cell-3534396446b0c46b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 4. Cluster the digits dataset using K-means and evaluate using adjusted rand index (ARI) (1 point)\n",
    "\n",
    "Go ahead and cluster the dataset using K-means. \n",
    "\n",
    "Set the number of clusters to ten and and the random_state to 126:\n",
    "```python\n",
    "KMeans(n_clusters=10, random_state=126)\n",
    "```\n",
    "\n",
    "Evaluate your clusters using the ARI. You can import the ARI function from sklearn.metrics:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "```\n",
    "\n",
    "Save the ARI to the variable *score*. Save the KMeans model to the variable *model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "368dcd76be58e9af7c2b673198df4be5",
     "grade": false,
     "grade_id": "cell-d707c326d2bdb279",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "809de4a2705853c950e4b530decdafcc",
     "grade": true,
     "grade_id": "cell-42b2feb509ff1a9d",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(score, float)\n",
    "assert np.isclose(score, 0.483, atol=0.1)\n",
    "assert len(model.labels_) == 1797\n",
    "assert sum(model.labels_) == 5881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53514315cc6d88eb403c4384521b24ad",
     "grade": false,
     "grade_id": "cell-c4e12f5df445e7cc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 5. How does the ARI change when you alter the K-means parameters?\n",
    "### Optional and ungraded.\n",
    "\n",
    "Explore the effect on the ARI of changing the KMeans parameters, such as: init, n_init, max_iter.\n",
    "\n",
    "Compare to other evaluations, such as: homogeneity score, completeness score, and the silhouette coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "481147fc8aff425c12b40819fa17fc29",
     "grade": false,
     "grade_id": "cell-c4e12f5df447cc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 6. Clustering as a classifier?\n",
    "### Optional and ungraded.\n",
    "\n",
    "Can you use clustering as a classifier for the digits dataset? How does it compare to some of the classifiers you used last week, such as random forest?\n",
    "\n",
    "One way of comparing the methods would be interpreting the results of classification as cluster label assignment and using ARI for comparison.\n",
    "\n",
    "Alternatively, you can use cluster labels as new features added to the dataset, for instance with one-hot-encoding sklearn.preprocessing.OneHotEncoder() so that:\n",
    "    1. labels = clustering.fit_predict(X)\n",
    "    2. new columns = OneHotEncoder(labels)\n",
    "    3. add new columns to X with np.hstack() or similar approach\n",
    "    4. classifier.fit(X, y)\n",
    "    5. evaluate performance improvement, if any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7. Implement K-means\n",
    "### Optional and ungraded.\n",
    "\n",
    "Can you write your own simple implementation of K-means algorithm with .fit_predict(X) method that returns cluster labels for dataset X?\n",
    "\n",
    "```\n",
    "class MyKmeans(object):\n",
    "    def __init__(self, n_clusters):\n",
    "        pass\n",
    "\n",
    "    def fit_predict(X):\n",
    "        return labels\n",
    "        \n",
    "```\n",
    "\n",
    "Your .fit_predict() method can implement Lloyds algorithm, for instance, that consists of the following three steps:\n",
    "\n",
    "1. assign random values for k means $m_1,...,m_k$\n",
    "\n",
    "Make iterations (while loop or for loop) that alternate between:\n",
    "2. Assignment step: Assign each example in X to the cluster whose mean has the least squared Euclidean distance, this is intuitively the \"nearest\" mean $m$\n",
    "\n",
    "3. Update step: Calculate the new means $m$ (centroids) of the examples in the new clusters.\n",
    "\n",
    "The process typically stops when there is no update happening in Update step or when a certain number of iterations is reached.\n",
    "\n",
    "The index $i$ of a mean $m_i$ assigned to example is interpreted as its cluster label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
